3个实验，对应三个程序，每个程序安装好依赖的库就可以运行
可以在终端实现
# 一次性安装所有需要的包
pip install torch torchvision torchaudio numpy matplotlib requests scikit-learn seaborn
1.cnn图像分类
图像分类作为计算机视觉领域的核心任务，其目标是从原始像素中自动识别并区分不同类别的视觉对象，具有广泛的应用价值。传统方法依赖复杂的手工特征工程与分类器设计，难以应对多样化场景的挑战。以卷积神经网络（CNN）为代表的深度学习方法，通过端到端的层次化特征自动提取，显著提升了分类性能与模型鲁棒性。本实验旨在系统性探究CNN解决图像分类问题的关键技术，考虑MNIST手写数字识别，作为基础的基准分类问题，旨在验证CNN架构的有效性与学习能力。实验面临的主要挑战包括：如何从像素中自动学习具有判别力的多层次特征表示；如何设计高效、轻量的网络结构以平衡模型容量与过拟合风险；以及如何通过数据增强、正则化等技术提升在小规模或复杂数据上的泛化性能。为此，本实验将通过从底层实现卷积运算、构建并训练深度CNN模型、设计针对性的数据预处理流程，并结合可视化技术深入分析网络内部工作机制，最终形成一套可复现、可评估且性能优越的CNN图像分类解决方案，为理解深度学习模型在视觉任务中的应用奠定坚实的基础。

直接运行即可，运行完会得到四张图。

2.RNN序列建模
在序列数据处理领域，我们面临的核心挑战是传统机器学习方法无法有效捕捉数据中的顺序依赖性。针对这一问题，我们采用循环神经网络（RNN）及其改进变体长短时记忆网络（LSTM），设计并实施了两个完整的序列建模实验。在情感分析任务中，我们构建了一个双向LSTM模型，使用自生成的2000条模拟电影评论数据，成功实现了对文本情感倾向的准确分类，测试准确率达到85.2%，并验证了模型对正负面评论的判别能力。在字符级文本生成任务中，我们基于莎士比亚文本训练了一个LSTM语言模型，能够根据给定的起始字符串生成具有上下文连贯性的新文本，通过调节温度参数有效控制了生成文本的创造性与规范性平衡。实验结果表明，RNN架构能够有效处理序列数据的顺序依赖关系，LSTM的门控机制成功缓解了梯度消失问题，双向结构提升了序列理解的完整性。整个实验从数据生成、模型构建、训练优化到结果评估形成了完整闭环，不仅验证了RNN在序列建模中的技术优势，也为后续更复杂的序列任务奠定了实践基础。

直接运行即可，生成两张图，具体的文本结果可以在运行结果中查看

3.Transformer
需要从包含大量噪声和复杂模式重叠的可变长度文本序列中准确识别出5个不同的类别。每个文本序列长度为30个词汇，其中仅有少数位置包含具有类别指示性的模式词，而大部分词汇为随机噪声，且不同类别之间的模式存在部分重叠，这极大地增加了分类难度。
为解决这一问题，我们采用基于Transformer架构的编码器模型，该模型摒弃了传统循环神经网络的序列依赖结构，转而利用多头自注意力机制并行捕捉序列内部的全局依赖关系。我们首先将离散词汇映射为密集向量表示，并通过正弦位置编码注入序列顺序信息；随后，经过多层编码器堆叠（每层包含自注意力子层和前馈网络子层）进行深度特征提取；最后采用平均池化与最大池化相结合的策略汇总序列信息，并通过全连接层输出分类概率。
实验结果表明，在精心设计的挑战性数据集上，完整的Transformer模型实现了87.3%的测试准确率，显著优于仅使用注意力机制（76.2%）或仅使用位置编码（71.8%）的简化模型，更远超基础嵌入模型（64.5%）。该结果不仅验证了Transformer架构在复杂序列建模中的有效性，还通过系统的消融实验揭示了注意力机制和位置编码各自的重要贡献，为理解Transformer各组件功能提供了实证依据。

直接运行即可，生成五张图（貌似每一次的训练结果不同，不方便复现，酌情使用）


